# Deepaffects

DeepAffects enables developers to analyze conversational audio by applying powerful machine learning models offered as a set of easy to use REST APIs. We support apis like: Interaction Analytics, Speaker Diarization, Emotion Recognition, Speech to Text etc. Checkout [developer docs](https://developers. deepaffects. com/docs) for more details. DeepAffects speech analysis platform supports automated multi-speaker recognition, voiceprints, emotions & intents from natural conversations

##  🔗 Links
**Docs / Website**: https://www.deepaffects.com

## 🧬 Deepaffects Specification:
**Type**: N/A - [Add ➕](https://github.com/apis-list/apis-list/edit/main/apis.yaml#L4879)  
**URI**: N/A - [Add ➕](https://github.com/apis-list/apis-list/edit/main/apis.yaml#L4879)  
**Version**: N/A - [Add ➕](https://github.com/apis-list/apis-list/edit/main/apis.yaml#L4879)

## 💬 Deepaffects Discussion:
Not yet started. [Start discussion ➡️](https://github.com/apis-list/apis-list/discussions/new)

## 🗂️ Libraries
### JavaScript, Node.js
- DeepAffects Node.js SDK: [Documentation](https://github.com/SEERNET/deepaffects-node), [Source code](https://www.npmjs.com/package/deep-affects)
### Python
- DeepAffects Python SDK: [Documentation](https://github.com/SEERNET/deepaffects-python), [Source code](https://pypi.org/project/deepaffects/1.1.1/)


## 🗄️ Categories:
- [AI & ML](https://github.com/apis-list/apis-list#ai--ml-)- [Music & Audio](https://github.com/apis-list/apis-list#music--audio-)- [Recognition](https://github.com/apis-list/apis-list#recognition-)- [Text Analysis & Tools](https://github.com/apis-list/apis-list#text-analysis--tools-)

🔙  [Back to List](https://github.com/apis-list/apis-list)
